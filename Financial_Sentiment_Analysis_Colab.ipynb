{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a06b8f3",
   "metadata": {},
   "source": [
    "## Cell 1: Install Dependencies & Clone Repository\n",
    "\n",
    "Run this cell first to set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236bcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch transformers vaderSentiment pandas matplotlib seaborn jupyter kaggle\n",
    "\n",
    "# Setup Kaggle authentication using Colab's userdata feature\n",
    "# Go to the key icon (ðŸ”‘) on the left sidebar â†’ Add \"KAGGLE_USERNAME\" and \"KAGGLE_KEY\"\n",
    "# Get these from: kaggle.com â†’ Account â†’ Create New API Token\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
    "    os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
    "    print(\"âœ… Kaggle credentials loaded from Colab secrets\")\n",
    "    kaggle_enabled = True\n",
    "except:\n",
    "    print(\"âš ï¸  Kaggle credentials not found in Colab secrets\")\n",
    "    print(\"   Add KAGGLE_USERNAME and KAGGLE_KEY in the ðŸ”‘ Secrets panel\")\n",
    "    print(\"   Or use GitHub sample data instead\")\n",
    "    kaggle_enabled = False\n",
    "\n",
    "# Clone the repository (for code modules)\n",
    "!git clone https://github.com/annageiser/Sentiment-Analyzer.git 2>/dev/null || (cd Sentiment-Analyzer && git pull -q)\n",
    "\n",
    "# Change to project directory\n",
    "%cd /content/Sentiment-Analyzer\n",
    "!mkdir -p data\n",
    "\n",
    "# Option 1: Download from Kaggle (if credentials available)\n",
    "if kaggle_enabled:\n",
    "    print(\"\\nðŸ“¥ Downloading SEC filings from Kaggle...\")\n",
    "    # Example: Replace with your preferred dataset\n",
    "    # !kaggle datasets download -d username/dataset-name -p data/ --unzip\n",
    "    print(\"âš ï¸  Uncomment and replace 'username/dataset-name' with actual Kaggle dataset\")\n",
    "    print(\"   Example datasets:\")\n",
    "    print(\"   - abhishekjoshi8/sec-edgar-filings-dataset\")\n",
    "    print(\"   - seantorres/sec-10-k-financial-statements\")\n",
    "\n",
    "# Option 2: Use GitHub sample data (fallback)\n",
    "print(\"\\nðŸ“¥ Using sample data from GitHub repository...\")\n",
    "\n",
    "# Verify project structure\n",
    "!echo \"\\n=== Project Files ===\"\n",
    "!ls -la *.py *.txt *.ipynb 2>/dev/null | grep -v total\n",
    "!echo \"\\n=== Data Files ===\"\n",
    "!ls -la data/ | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b999896",
   "metadata": {},
   "source": [
    "## Cell 2: Setup Environment & Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import from local modules\n",
    "from sentiment_analysis import FinancialSentimentAnalyzer, load_filing_data\n",
    "from batch_analysis import process_batch\n",
    "\n",
    "# Configure paths for Colab\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Financial Sentiment Analysis - Google Colab Demo\")\n",
    "print(f\"Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb38db",
   "metadata": {},
   "source": [
    "## Cell 3: Load Sample SEC Filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load first available SEC filing\n",
    "available_samples = list(DATA_DIR.glob(\"*.json\"))\n",
    "\n",
    "if available_samples:\n",
    "    SAMPLE_FILE = str(available_samples[0])\n",
    "    print(f\"âœ“ Using sample file: {available_samples[0].name}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Warning: No sample files found in {DATA_DIR}\")\n",
    "    SAMPLE_FILE = None\n",
    "\n",
    "SECTIONS_OF_INTEREST = ['item_7', 'item_1A']\n",
    "\n",
    "if SAMPLE_FILE:\n",
    "    try:\n",
    "        filing_data = load_filing_data(SAMPLE_FILE, SECTIONS_OF_INTEREST)\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"âœ“ Loaded filing data with {len(filing_data)} sections\")\n",
    "        print(f\"  Available sections: {', '.join(filing_data.keys())}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Display section sizes\n",
    "        for section, text in filing_data.items():\n",
    "            print(f\"  {section}: {len(text):,} characters\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸  File not found: {SAMPLE_FILE}\")\n",
    "        filing_data = {}\n",
    "else:\n",
    "    filing_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a1f8f",
   "metadata": {},
   "source": [
    "## Cell 4: Initialize FinBERT Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analyzer (FinBERT model)\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nðŸ”§ Initializing Sentiment Analyzer...\")\n",
    "print(\"(First run will download FinBERT model ~500MB)\")\n",
    "print()\n",
    "\n",
    "analyzer = FinancialSentimentAnalyzer()\n",
    "\n",
    "print(\"âœ… Ready to analyze filings\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d4c84",
   "metadata": {},
   "source": [
    "## Cell 5: Analyze Sentiment Per Section\n",
    "\n",
    "**Key Question**: Is the tone consistent across sections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0627b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filing_data:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nðŸ“Š SENTIMENT COMPARISON - Cross-Section Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    comparison_data = []\n",
    "    \n",
    "    for section_name, section_text in filing_data.items():\n",
    "        print(f\"\\n  Analyzing {section_name}...\")\n",
    "        section_results = analyzer.analyze_text(section_text)\n",
    "        section_agg = analyzer.aggregate_sentiment(section_results)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Section': section_name.replace('item_', 'Item ').upper(),\n",
    "            'Sentiment': section_agg['label'],\n",
    "            'Score': f\"{section_agg['score']:.3f}\",\n",
    "            'Confidence': f\"{section_agg['confidence']:.3f}\",\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    # Check for inconsistencies\n",
    "    sentiments = [d['Sentiment'] for d in comparison_data]\n",
    "    if len(set(sentiments)) > 1:\n",
    "        print(f\"âš ï¸  ALERT: Sentiment differs across sections - potential inconsistency detected!\")\n",
    "    else:\n",
    "        print(f\"âœ… Consistent tone: All sections show {sentiments[0]} sentiment\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"âš ï¸  No filing data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017fefe",
   "metadata": {},
   "source": [
    "## Cell 6: Visualize Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7aa769",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'comparison_df' in locals() and len(comparison_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Convert Score and Confidence to float for plotting\n",
    "    comparison_df['Score_float'] = comparison_df['Score'].astype(float)\n",
    "    comparison_df['Confidence_float'] = comparison_df['Confidence'].astype(float)\n",
    "    \n",
    "    # Sentiment scores\n",
    "    colors = ['#2ecc71' if x > 0 else '#e74c3c' if x < 0 else '#95a5a6' \n",
    "              for x in comparison_df['Score_float']]\n",
    "    axes[0].bar(comparison_df['Section'], comparison_df['Score_float'], color=colors)\n",
    "    axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    axes[0].set_title('Sentiment Score by Section', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Score (Positive â†’ Negative)')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Confidence scores\n",
    "    axes[1].bar(comparison_df['Section'], comparison_df['Confidence_float'], color='#3498db')\n",
    "    axes[1].set_title('Analysis Confidence by Section', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Confidence Score')\n",
    "    axes[1].set_ylim([0, 1.0])\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸  Insufficient data for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4336c",
   "metadata": {},
   "source": [
    "## Cell 7: Risk Assessment\n",
    "\n",
    "**Key Question**: Are there red flags or risk indicators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_business_risks(sentiment_results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Assess financial risks from business perspective.\n",
    "    \n",
    "    Returns: Dictionary with risk level, specific risks, and recommendations\n",
    "    \"\"\"\n",
    "    risks = []\n",
    "    severity = \"LOW\"\n",
    "    \n",
    "    positive_ratio = sentiment_results.get('positive_ratio', 0)\n",
    "    negative_ratio = sentiment_results.get('negative_ratio', 0)\n",
    "    confidence = sentiment_results.get('confidence', 0)\n",
    "    \n",
    "    # Risk 1: Over-optimism (potential misleading statements)\n",
    "    if positive_ratio > 0.70:\n",
    "        risks.append(\"ðŸ”´ OVER-OPTIMISM: Unusually positive tone may mask underlying issues\")\n",
    "        severity = \"HIGH\"\n",
    "    \n",
    "    # Risk 2: Distress signals\n",
    "    if negative_ratio > 0.60:\n",
    "        risks.append(\"ðŸ”´ DISTRESS SIGNALS: High negative sentiment may indicate financial problems\")\n",
    "        severity = \"HIGH\"\n",
    "    \n",
    "    # Risk 3: Low confidence (vague/unclear disclosures)\n",
    "    if confidence < 0.30:\n",
    "        risks.append(\"ðŸŸ  VAGUE LANGUAGE: Low confidence suggests unclear or inconsistent disclosures\")\n",
    "        severity = \"MEDIUM\" if severity == \"LOW\" else severity\n",
    "    \n",
    "    # Risk 4: Mixed messaging\n",
    "    if 0.35 < positive_ratio < 0.65 and 0.35 < negative_ratio < 0.65:\n",
    "        risks.append(\"ðŸŸ¡ MIXED SIGNALS: Conflicting narratives - company is hedging statements\")\n",
    "        severity = \"MEDIUM\" if severity == \"LOW\" else severity\n",
    "    \n",
    "    return {\n",
    "        'severity': severity,\n",
    "        'risks': risks if risks else [\"âœ… LOW RISK: Consistent, clear, moderate tone\"],\n",
    "        'confidence': confidence\n",
    "    }\n",
    "\n",
    "# Analyze all sections for risks\n",
    "if filing_data:\n",
    "    print(\"\\nðŸš¨ RISK ASSESSMENT - Executive Summary\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    all_risks = []\n",
    "    for section_name, section_text in filing_data.items():\n",
    "        section_results = analyzer.analyze_text(section_text)\n",
    "        section_agg = analyzer.aggregate_sentiment(section_results)\n",
    "        section_risks = assess_business_risks(section_agg)\n",
    "        \n",
    "        print(f\"\\nðŸ“Œ {section_name.replace('item_', 'Item ').upper()}\")\n",
    "        print(f\"   Risk Level: {section_risks['severity']} | Confidence: {section_risks['confidence']:.1%}\")\n",
    "        for risk in section_risks['risks']:\n",
    "            print(f\"   {risk}\")\n",
    "        all_risks.append(section_risks)\n",
    "    \n",
    "    # Overall assessment\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ðŸŽ¯ OVERALL ASSESSMENT\")\n",
    "    overall_severity = max([r['severity'] for r in all_risks], key=lambda x: {'LOW': 0, 'MEDIUM': 1, 'HIGH': 2}[x])\n",
    "    print(f\"Risk Level: {overall_severity}\")\n",
    "    \n",
    "    if overall_severity == \"HIGH\":\n",
    "        print(\"âš ï¸  RECOMMENDATION: Conduct thorough audit of disclosure statements\")\n",
    "    elif overall_severity == \"MEDIUM\":\n",
    "        print(\"âš ï¸  RECOMMENDATION: Review specific sections flagged above\")\n",
    "    else:\n",
    "        print(\"âœ… RECOMMENDATION: Standard review procedures sufficient\")\n",
    "else:\n",
    "    print(\"âš ï¸  No filing data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd43b5",
   "metadata": {},
   "source": [
    "## Cell 8: Detailed MD&A Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filing_data and 'item_7' in filing_data:\n",
    "    print(\"\\nðŸ“‹ DETAILED MD&A ANALYSIS (Management Discussion & Analysis)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    mdna_text = filing_data['item_7']\n",
    "    print(\"\\n  Analyzing MD&A section...\")\n",
    "    mdna_results = analyzer.analyze_text(mdna_text)\n",
    "    mdna_aggregate = analyzer.aggregate_sentiment(mdna_results)\n",
    "    \n",
    "    print(f\"\\nText Length: {len(mdna_text):,} characters\")\n",
    "    print(f\"Chunks Analyzed: {len(mdna_results)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Sentiment Breakdown:\")\n",
    "    distribution = mdna_aggregate['sentiment_distribution']\n",
    "    total = sum(distribution.values())\n",
    "    for sentiment, count in sorted(distribution.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / total * 100) if total > 0 else 0\n",
    "        print(f\"   {sentiment:12s}: {count:3d} chunks ({percentage:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Overall Assessment:\")\n",
    "    print(f\"   Sentiment: {mdna_aggregate['label']}\")\n",
    "    print(f\"   Score: {mdna_aggregate['score']:.3f} (positive=1.0, negative=-1.0)\")\n",
    "    print(f\"   Confidence: {mdna_aggregate['confidence']:.1%}\")\n",
    "    \n",
    "    # Save for downstream analysis\n",
    "    mdna_analysis = {\n",
    "        'results': mdna_results,\n",
    "        'aggregate': mdna_aggregate\n",
    "    }\n",
    "else:\n",
    "    print(\"âš ï¸  MD&A section not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40672386",
   "metadata": {},
   "source": [
    "## Cell 9: Business Actionable Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a08a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Œ KEY BUSINESS INSIGHTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "insights = [\n",
    "    (\"AUDITORS\", [\n",
    "        \"Use sentiment inconsistency detection to identify sections requiring deeper audit\",\n",
    "        \"Flag unusual optimism in problematic business segments\",\n",
    "        \"Verify claims in sections with vague or conflicting language\"\n",
    "    ]),\n",
    "    (\"INVESTORS\", [\n",
    "        \"Compare sentiment tone to financial metrics (income, cash flow) for coherence\",\n",
    "        \"Watch for over-optimism relative to risk factor disclosures\",\n",
    "        \"Identify companies hedging negative news with cautious language\"\n",
    "    ]),\n",
    "    (\"REGULATORS\", [\n",
    "        \"Monitor for systematically misleading narratives across filings\",\n",
    "        \"Compare sentiment trends year-over-year for consistency\",\n",
    "        \"Cross-check narrative claims against quantitative financial data\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "for stakeholder, use_cases in insights:\n",
    "    print(f\"\\nðŸ‘¥ {stakeholder}\")\n",
    "    for i, case in enumerate(use_cases, 1):\n",
    "        print(f\"   {i}. {case}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab680047",
   "metadata": {},
   "source": [
    "## Cell 10: Batch Processing (Multiple Companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸš€ BATCH PROCESSING - Multiple Companies\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Demo: First show single filing analysis (already done above)\n",
    "print(\"\\nðŸ“Œ SINGLE FILING (Already Analyzed)\")\n",
    "print(\"-\" * 70)\n",
    "if SAMPLE_FILE:\n",
    "    print(f\"File: {SAMPLE_FILE}\")\n",
    "    if 'overall_severity' in locals():\n",
    "        print(f\"Overall Risk Level: {overall_severity}\")\n",
    "    print(\"âœ… Use this when auditing or analyzing a specific company\\n\")\n",
    "\n",
    "# Demo: Now show batch processing capability\n",
    "data_dir = Path(\"data\")\n",
    "output_dir = Path(\"output\")\n",
    "available_files = list(data_dir.glob(\"*.json\"))\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if len(available_files) > 1:\n",
    "    print(f\"ðŸ“Œ BATCH PROCESSING ({len(available_files)} companies found)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"Processing all filings in data/ directory...\\n\")\n",
    "    \n",
    "    # Generate timestamped output filename\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_file = f\"output/batch_analysis_{timestamp}.csv\"\n",
    "    \n",
    "    # Run batch analysis\n",
    "    process_batch(\n",
    "        input_dir='data/',\n",
    "        output_file=output_file,\n",
    "        sections=['item_7', 'item_1A']\n",
    "    )\n",
    "    \n",
    "    # Load and display results\n",
    "    batch_df = pd.read_csv(output_file)\n",
    "    print(\"\\nâœ… Batch Analysis Results:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Show summary statistics\n",
    "    if 'overall_sentiment' in batch_df.columns:\n",
    "        print(f\"\\nProcessed {len(batch_df['company_id'].unique())} companies\")\n",
    "        print(f\"Analyzed {len(batch_df)} section-level entries\")\n",
    "        print(f\"\\nResults saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample results\n",
    "        print(\"\\nSample Results (first 10 entries):\")\n",
    "        display_cols = ['company_id', 'section', 'overall_sentiment', 'sentiment_score', 'confidence']\n",
    "        available_cols = [col for col in display_cols if col in batch_df.columns]\n",
    "        print(batch_df[available_cols].head(10).to_string(index=False))\n",
    "        \n",
    "        print(\"\\nâœ… Use batch processing when:\")\n",
    "        print(\"   - Analyzing industry trends\")\n",
    "        print(\"   - Comparing multiple companies\")\n",
    "        print(\"   - Identifying outliers (unusually optimistic/pessimistic)\")\n",
    "        print(\"   - Generating regulatory reports\")\n",
    "else:\n",
    "    print(\"ðŸ“Œ BATCH PROCESSING\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Only {len(available_files)} file(s) available in data/ directory\")\n",
    "    print(\"\\nâœ… To run batch processing:\")\n",
    "    print(\"   1. Add more SEC filings to data/ directory\")\n",
    "    print(\"   2. Run: process_batch(\")\n",
    "    print(\"         input_dir='data/',\")\n",
    "    print(\"         output_file='output/batch_results.csv',\")\n",
    "    print(\"         sections=['item_7', 'item_1A']\")\n",
    "    print(\"      )\")\n",
    "    print(\"\\nâœ… Batch processing provides:\")\n",
    "    print(\"   - Cross-company sentiment comparison\")\n",
    "    print(\"   - Industry trend analysis\")\n",
    "    print(\"   - Risk outlier identification\")\n",
    "    print(\"   - Exportable results (CSV in output/ folder)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012d8f2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Demo Complete!**\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Single Filing Analysis** - Load and analyze a SEC 10-K filing\n",
    "2. **Sentiment Comparison** - Compare tone across sections\n",
    "3. **Risk Assessment** - Flag business risks and inconsistencies\n",
    "4. **Detailed Analysis** - Deep dive into MD&A section\n",
    "5. **Stakeholder Insights** - Business value for Auditors, Investors, Regulators\n",
    "6. **Batch Processing** - Scale analysis to multiple companies\n",
    "\n",
    "### For Your Assignment:\n",
    "- **Deliverable 1 (Prototype)**: This notebook + `sentiment_analysis.py` + `batch_analysis.py`\n",
    "- **Deliverable 2 (Presentation)**: See `Documentations/PRESENTATION_GUIDE.md`\n",
    "\n",
    "### To Share This Demo:\n",
    "1. Save this notebook to your Google Colab\n",
    "2. Click \"Share\" and set permissions\n",
    "3. Copy the link and include in your presentation slides\n",
    "4. During presentation, just click \"Run all\" cells\n",
    "\n",
    "---\n",
    "\n",
    "**HS25 Big Data Assignment - Group Work Part 2**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
