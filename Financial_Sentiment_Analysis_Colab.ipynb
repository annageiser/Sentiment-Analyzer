{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a06b8f3",
      "metadata": {
        "id": "9a06b8f3"
      },
      "source": [
        "## Cell 1: Install Dependencies & Clone Repository\n",
        "\n",
        "Run this cell first to set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "236bcd0d",
      "metadata": {
        "id": "236bcd0d",
        "outputId": "78cef924-306d-4bba-e989-828e4bdcd619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  Kaggle credentials not found in Colab secrets\n",
            "   Add KAGGLE_USERNAME and KAGGLE_KEY in the üîë Secrets panel\n",
            "   Or use GitHub sample data instead\n",
            "/content/Sentiment-Analyzer\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/pranjalverma08/sec-edgar-annual-financial-filings-2021?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62.8M/62.8M [00:00<00:00, 115MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì• Using sample data from GitHub repository...\n",
            "\\n=== Project Files ===\n",
            "-rw-r--r-- 1 root root  22561 Dec  8 14:17 Financial_Sentiment_Analysis_Colab.ipynb\n",
            "-rw-r--r-- 1 root root 137659 Dec  8 14:17 financial_sentiment_analysis.ipynb\n",
            "-rw-r--r-- 1 root root    226 Dec  8 14:17 requirements.txt\n",
            "\\n=== Data Files ===\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Dec  8 14:17 .\n",
            "drwxr-xr-x 6 root root 4096 Dec  8 14:18 ..\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch transformers vaderSentiment pandas matplotlib seaborn jupyter kaggle\n",
        "\n",
        "# Clone the repository (for code modules)\n",
        "!git clone https://github.com/annageiser/Sentiment-Analyzer.git 2>/dev/null || (cd Sentiment-Analyzer && git pull -q)\n",
        "\n",
        "# Change to project directory\n",
        "%cd /content/Sentiment-Analyzer\n",
        "!mkdir -p data\n",
        "\n",
        "# Option 1: Download from Kaggle (if credentials available)\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"pranjalverma08/sec-edgar-annual-financial-filings-2021\")\n",
        "\n",
        "# Option 2: Use GitHub sample data (fallback)\n",
        "print(\"\\nüì• Using sample data from GitHub repository...\")\n",
        "\n",
        "# Verify project structure\n",
        "!echo \"\\n=== Project Files ===\"\n",
        "!ls -la *.py *.txt *.ipynb 2>/dev/null | grep -v total\n",
        "!echo \"\\n=== Data Files ===\"\n",
        "!ls -la data/ | head -10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b999896",
      "metadata": {
        "id": "8b999896"
      },
      "source": [
        "## Cell 2: Setup Environment & Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c41b8426",
      "metadata": {
        "id": "c41b8426",
        "outputId": "428fb57d-0573-403f-b9eb-d47564f0471f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sentiment_analysis'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3505140813.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Import from local modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentiment_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFinancialSentimentAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_filing_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbatch_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocess_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentiment_analysis'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Tuple\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import from local modules\n",
        "from sentiment_analysis import FinancialSentimentAnalyzer, load_filing_data\n",
        "from batch_analysis import process_batch\n",
        "\n",
        "# Configure paths for Colab\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Configure visualization\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Financial Sentiment Analysis - Google Colab Demo\")\n",
        "print(f\"Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(\"=\" * 70)\n",
        "print(\"‚úÖ Environment ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fb38db",
      "metadata": {
        "id": "00fb38db"
      },
      "source": [
        "## Cell 3: Load Sample SEC Filing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd87b437",
      "metadata": {
        "id": "bd87b437"
      },
      "outputs": [],
      "source": [
        "# Find and load first available SEC filing\n",
        "available_samples = list(DATA_DIR.glob(\"*.json\"))\n",
        "\n",
        "if available_samples:\n",
        "    SAMPLE_FILE = str(available_samples[0])\n",
        "    print(f\"‚úì Using sample file: {available_samples[0].name}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Warning: No sample files found in {DATA_DIR}\")\n",
        "    SAMPLE_FILE = None\n",
        "\n",
        "SECTIONS_OF_INTEREST = ['item_7', 'item_1A']\n",
        "\n",
        "if SAMPLE_FILE:\n",
        "    try:\n",
        "        filing_data = load_filing_data(SAMPLE_FILE, SECTIONS_OF_INTEREST)\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"‚úì Loaded filing data with {len(filing_data)} sections\")\n",
        "        print(f\"  Available sections: {', '.join(filing_data.keys())}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Display section sizes\n",
        "        for section, text in filing_data.items():\n",
        "            print(f\"  {section}: {len(text):,} characters\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ö†Ô∏è  File not found: {SAMPLE_FILE}\")\n",
        "        filing_data = {}\n",
        "else:\n",
        "    filing_data = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c16a1f8f",
      "metadata": {
        "id": "c16a1f8f"
      },
      "source": [
        "## Cell 4: Initialize FinBERT Analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866bec9a",
      "metadata": {
        "id": "866bec9a"
      },
      "outputs": [],
      "source": [
        "# Initialize the sentiment analyzer (FinBERT model)\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüîß Initializing Sentiment Analyzer...\")\n",
        "print(\"(First run will download FinBERT model ~500MB)\")\n",
        "print()\n",
        "\n",
        "analyzer = FinancialSentimentAnalyzer()\n",
        "\n",
        "print(\"‚úÖ Ready to analyze filings\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca2d4c84",
      "metadata": {
        "id": "ca2d4c84"
      },
      "source": [
        "## Cell 5: Analyze Sentiment Per Section\n",
        "\n",
        "**Key Question**: Is the tone consistent across sections?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0627b32",
      "metadata": {
        "id": "e0627b32"
      },
      "outputs": [],
      "source": [
        "if filing_data:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nüìä SENTIMENT COMPARISON - Cross-Section Analysis\")\n",
        "    print(\"=\" * 70)\n",
        "    comparison_data = []\n",
        "\n",
        "    for section_name, section_text in filing_data.items():\n",
        "        print(f\"\\n  Analyzing {section_name}...\")\n",
        "        section_results = analyzer.analyze_text(section_text)\n",
        "        section_agg = analyzer.aggregate_sentiment(section_results)\n",
        "\n",
        "        comparison_data.append({\n",
        "            'Section': section_name.replace('item_', 'Item ').upper(),\n",
        "            'Sentiment': section_agg['label'],\n",
        "            'Score': f\"{section_agg['score']:.3f}\",\n",
        "            'Confidence': f\"{section_agg['confidence']:.3f}\",\n",
        "        })\n",
        "\n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "    # Check for inconsistencies\n",
        "    sentiments = [d['Sentiment'] for d in comparison_data]\n",
        "    if len(set(sentiments)) > 1:\n",
        "        print(f\"‚ö†Ô∏è  ALERT: Sentiment differs across sections - potential inconsistency detected!\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Consistent tone: All sections show {sentiments[0]} sentiment\")\n",
        "    print(\"=\" * 70)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No filing data available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4017fefe",
      "metadata": {
        "id": "4017fefe"
      },
      "source": [
        "## Cell 6: Visualize Sentiment Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f7aa769",
      "metadata": {
        "id": "5f7aa769"
      },
      "outputs": [],
      "source": [
        "if 'comparison_df' in locals() and len(comparison_df) > 0:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Convert Score and Confidence to float for plotting\n",
        "    comparison_df['Score_float'] = comparison_df['Score'].astype(float)\n",
        "    comparison_df['Confidence_float'] = comparison_df['Confidence'].astype(float)\n",
        "\n",
        "    # Sentiment scores\n",
        "    colors = ['#2ecc71' if x > 0 else '#e74c3c' if x < 0 else '#95a5a6'\n",
        "              for x in comparison_df['Score_float']]\n",
        "    axes[0].bar(comparison_df['Section'], comparison_df['Score_float'], color=colors)\n",
        "    axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "    axes[0].set_title('Sentiment Score by Section', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_ylabel('Score (Positive ‚Üí Negative)')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Confidence scores\n",
        "    axes[1].bar(comparison_df['Section'], comparison_df['Confidence_float'], color='#3498db')\n",
        "    axes[1].set_title('Analysis Confidence by Section', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_ylabel('Confidence Score')\n",
        "    axes[1].set_ylim([0, 1.0])\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Insufficient data for visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9b4336c",
      "metadata": {
        "id": "e9b4336c"
      },
      "source": [
        "## Cell 7: Risk Assessment\n",
        "\n",
        "**Key Question**: Are there red flags or risk indicators?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a17a874",
      "metadata": {
        "id": "3a17a874"
      },
      "outputs": [],
      "source": [
        "def assess_business_risks(sentiment_results: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Assess financial risks from business perspective.\n",
        "\n",
        "    Returns: Dictionary with risk level, specific risks, and recommendations\n",
        "    \"\"\"\n",
        "    risks = []\n",
        "    severity = \"LOW\"\n",
        "\n",
        "    positive_ratio = sentiment_results.get('positive_ratio', 0)\n",
        "    negative_ratio = sentiment_results.get('negative_ratio', 0)\n",
        "    confidence = sentiment_results.get('confidence', 0)\n",
        "\n",
        "    # Risk 1: Over-optimism (potential misleading statements)\n",
        "    if positive_ratio > 0.70:\n",
        "        risks.append(\"üî¥ OVER-OPTIMISM: Unusually positive tone may mask underlying issues\")\n",
        "        severity = \"HIGH\"\n",
        "\n",
        "    # Risk 2: Distress signals\n",
        "    if negative_ratio > 0.60:\n",
        "        risks.append(\"üî¥ DISTRESS SIGNALS: High negative sentiment may indicate financial problems\")\n",
        "        severity = \"HIGH\"\n",
        "\n",
        "    # Risk 3: Low confidence (vague/unclear disclosures)\n",
        "    if confidence < 0.30:\n",
        "        risks.append(\"üü† VAGUE LANGUAGE: Low confidence suggests unclear or inconsistent disclosures\")\n",
        "        severity = \"MEDIUM\" if severity == \"LOW\" else severity\n",
        "\n",
        "    # Risk 4: Mixed messaging\n",
        "    if 0.35 < positive_ratio < 0.65 and 0.35 < negative_ratio < 0.65:\n",
        "        risks.append(\"üü° MIXED SIGNALS: Conflicting narratives - company is hedging statements\")\n",
        "        severity = \"MEDIUM\" if severity == \"LOW\" else severity\n",
        "\n",
        "    return {\n",
        "        'severity': severity,\n",
        "        'risks': risks if risks else [\"‚úÖ LOW RISK: Consistent, clear, moderate tone\"],\n",
        "        'confidence': confidence\n",
        "    }\n",
        "\n",
        "# Analyze all sections for risks\n",
        "if filing_data:\n",
        "    print(\"\\nüö® RISK ASSESSMENT - Executive Summary\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    all_risks = []\n",
        "    for section_name, section_text in filing_data.items():\n",
        "        section_results = analyzer.analyze_text(section_text)\n",
        "        section_agg = analyzer.aggregate_sentiment(section_results)\n",
        "        section_risks = assess_business_risks(section_agg)\n",
        "\n",
        "        print(f\"\\nüìå {section_name.replace('item_', 'Item ').upper()}\")\n",
        "        print(f\"   Risk Level: {section_risks['severity']} | Confidence: {section_risks['confidence']:.1%}\")\n",
        "        for risk in section_risks['risks']:\n",
        "            print(f\"   {risk}\")\n",
        "        all_risks.append(section_risks)\n",
        "\n",
        "    # Overall assessment\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéØ OVERALL ASSESSMENT\")\n",
        "    overall_severity = max([r['severity'] for r in all_risks], key=lambda x: {'LOW': 0, 'MEDIUM': 1, 'HIGH': 2}[x])\n",
        "    print(f\"Risk Level: {overall_severity}\")\n",
        "\n",
        "    if overall_severity == \"HIGH\":\n",
        "        print(\"‚ö†Ô∏è  RECOMMENDATION: Conduct thorough audit of disclosure statements\")\n",
        "    elif overall_severity == \"MEDIUM\":\n",
        "        print(\"‚ö†Ô∏è  RECOMMENDATION: Review specific sections flagged above\")\n",
        "    else:\n",
        "        print(\"‚úÖ RECOMMENDATION: Standard review procedures sufficient\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No filing data available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90cd43b5",
      "metadata": {
        "id": "90cd43b5"
      },
      "source": [
        "## Cell 8: Detailed MD&A Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f78e1e1",
      "metadata": {
        "id": "2f78e1e1"
      },
      "outputs": [],
      "source": [
        "if filing_data and 'item_7' in filing_data:\n",
        "    print(\"\\nüìã DETAILED MD&A ANALYSIS (Management Discussion & Analysis)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    mdna_text = filing_data['item_7']\n",
        "    print(\"\\n  Analyzing MD&A section...\")\n",
        "    mdna_results = analyzer.analyze_text(mdna_text)\n",
        "    mdna_aggregate = analyzer.aggregate_sentiment(mdna_results)\n",
        "\n",
        "    print(f\"\\nText Length: {len(mdna_text):,} characters\")\n",
        "    print(f\"Chunks Analyzed: {len(mdna_results)}\")\n",
        "\n",
        "    print(f\"\\nüìä Sentiment Breakdown:\")\n",
        "    distribution = mdna_aggregate['sentiment_distribution']\n",
        "    total = sum(distribution.values())\n",
        "    for sentiment, count in sorted(distribution.items(), key=lambda x: x[1], reverse=True):\n",
        "        percentage = (count / total * 100) if total > 0 else 0\n",
        "        print(f\"   {sentiment:12s}: {count:3d} chunks ({percentage:5.1f}%)\")\n",
        "\n",
        "    print(f\"\\nüéØ Overall Assessment:\")\n",
        "    print(f\"   Sentiment: {mdna_aggregate['label']}\")\n",
        "    print(f\"   Score: {mdna_aggregate['score']:.3f} (positive=1.0, negative=-1.0)\")\n",
        "    print(f\"   Confidence: {mdna_aggregate['confidence']:.1%}\")\n",
        "\n",
        "    # Save for downstream analysis\n",
        "    mdna_analysis = {\n",
        "        'results': mdna_results,\n",
        "        'aggregate': mdna_aggregate\n",
        "    }\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  MD&A section not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40672386",
      "metadata": {
        "id": "40672386"
      },
      "source": [
        "## Cell 9: Business Actionable Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a08a60",
      "metadata": {
        "id": "78a08a60"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìå KEY BUSINESS INSIGHTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "insights = [\n",
        "    (\"AUDITORS\", [\n",
        "        \"Use sentiment inconsistency detection to identify sections requiring deeper audit\",\n",
        "        \"Flag unusual optimism in problematic business segments\",\n",
        "        \"Verify claims in sections with vague or conflicting language\"\n",
        "    ]),\n",
        "    (\"INVESTORS\", [\n",
        "        \"Compare sentiment tone to financial metrics (income, cash flow) for coherence\",\n",
        "        \"Watch for over-optimism relative to risk factor disclosures\",\n",
        "        \"Identify companies hedging negative news with cautious language\"\n",
        "    ]),\n",
        "    (\"REGULATORS\", [\n",
        "        \"Monitor for systematically misleading narratives across filings\",\n",
        "        \"Compare sentiment trends year-over-year for consistency\",\n",
        "        \"Cross-check narrative claims against quantitative financial data\"\n",
        "    ])\n",
        "]\n",
        "\n",
        "for stakeholder, use_cases in insights:\n",
        "    print(f\"\\nüë• {stakeholder}\")\n",
        "    for i, case in enumerate(use_cases, 1):\n",
        "        print(f\"   {i}. {case}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab680047",
      "metadata": {
        "id": "ab680047"
      },
      "source": [
        "## Cell 10: Batch Processing (Multiple Companies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ed22a8",
      "metadata": {
        "id": "04ed22a8"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüöÄ BATCH PROCESSING - Multiple Companies\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Demo: First show single filing analysis (already done above)\n",
        "print(\"\\nüìå SINGLE FILING (Already Analyzed)\")\n",
        "print(\"-\" * 70)\n",
        "if SAMPLE_FILE:\n",
        "    print(f\"File: {SAMPLE_FILE}\")\n",
        "    if 'overall_severity' in locals():\n",
        "        print(f\"Overall Risk Level: {overall_severity}\")\n",
        "    print(\"‚úÖ Use this when auditing or analyzing a specific company\\n\")\n",
        "\n",
        "# Demo: Now show batch processing capability\n",
        "data_dir = Path(\"data\")\n",
        "output_dir = Path(\"output\")\n",
        "available_files = list(data_dir.glob(\"*.json\"))\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "if len(available_files) > 1:\n",
        "    print(f\"üìå BATCH PROCESSING ({len(available_files)} companies found)\")\n",
        "    print(\"-\" * 70)\n",
        "    print(\"Processing all filings in data/ directory...\\n\")\n",
        "\n",
        "    # Generate timestamped output filename\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    output_file = f\"output/batch_analysis_{timestamp}.csv\"\n",
        "\n",
        "    # Run batch analysis\n",
        "    process_batch(\n",
        "        input_dir='data/',\n",
        "        output_file=output_file,\n",
        "        sections=['item_7', 'item_1A']\n",
        "    )\n",
        "\n",
        "    # Load and display results\n",
        "    batch_df = pd.read_csv(output_file)\n",
        "    print(\"\\n‚úÖ Batch Analysis Results:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Show summary statistics\n",
        "    if 'overall_sentiment' in batch_df.columns:\n",
        "        print(f\"\\nProcessed {len(batch_df['company_id'].unique())} companies\")\n",
        "        print(f\"Analyzed {len(batch_df)} section-level entries\")\n",
        "        print(f\"\\nResults saved to: {output_file}\")\n",
        "\n",
        "        # Display sample results\n",
        "        print(\"\\nSample Results (first 10 entries):\")\n",
        "        display_cols = ['company_id', 'section', 'overall_sentiment', 'sentiment_score', 'confidence']\n",
        "        available_cols = [col for col in display_cols if col in batch_df.columns]\n",
        "        print(batch_df[available_cols].head(10).to_string(index=False))\n",
        "\n",
        "        print(\"\\n‚úÖ Use batch processing when:\")\n",
        "        print(\"   - Analyzing industry trends\")\n",
        "        print(\"   - Comparing multiple companies\")\n",
        "        print(\"   - Identifying outliers (unusually optimistic/pessimistic)\")\n",
        "        print(\"   - Generating regulatory reports\")\n",
        "else:\n",
        "    print(\"üìå BATCH PROCESSING\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"Only {len(available_files)} file(s) available in data/ directory\")\n",
        "    print(\"\\n‚úÖ To run batch processing:\")\n",
        "    print(\"   1. Add more SEC filings to data/ directory\")\n",
        "    print(\"   2. Run: process_batch(\")\n",
        "    print(\"         input_dir='data/',\")\n",
        "    print(\"         output_file='output/batch_results.csv',\")\n",
        "    print(\"         sections=['item_7', 'item_1A']\")\n",
        "    print(\"      )\")\n",
        "    print(\"\\n‚úÖ Batch processing provides:\")\n",
        "    print(\"   - Cross-company sentiment comparison\")\n",
        "    print(\"   - Industry trend analysis\")\n",
        "    print(\"   - Risk outlier identification\")\n",
        "    print(\"   - Exportable results (CSV in output/ folder)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c012d8f2",
      "metadata": {
        "id": "c012d8f2"
      },
      "source": [
        "## Summary\n",
        "\n",
        "‚úÖ **Demo Complete!**\n",
        "\n",
        "This notebook demonstrated:\n",
        "1. **Single Filing Analysis** - Load and analyze a SEC 10-K filing\n",
        "2. **Sentiment Comparison** - Compare tone across sections\n",
        "3. **Risk Assessment** - Flag business risks and inconsistencies\n",
        "4. **Detailed Analysis** - Deep dive into MD&A section\n",
        "5. **Stakeholder Insights** - Business value for Auditors, Investors, Regulators\n",
        "6. **Batch Processing** - Scale analysis to multiple companies\n",
        "\n",
        "### For Your Assignment:\n",
        "- **Deliverable 1 (Prototype)**: This notebook + `sentiment_analysis.py` + `batch_analysis.py`\n",
        "- **Deliverable 2 (Presentation)**: See `Documentations/PRESENTATION_GUIDE.md`\n",
        "\n",
        "### To Share This Demo:\n",
        "1. Save this notebook to your Google Colab\n",
        "2. Click \"Share\" and set permissions\n",
        "3. Copy the link and include in your presentation slides\n",
        "4. During presentation, just click \"Run all\" cells\n",
        "\n",
        "---\n",
        "\n",
        "**HS25 Big Data Assignment - Group Work Part 2**"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}